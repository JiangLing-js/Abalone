{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"},{"sourceId":8109578,"sourceType":"datasetVersion","datasetId":4790313}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T11:31:16.601548Z","iopub.execute_input":"2024-04-14T11:31:16.602924Z","iopub.status.idle":"2024-04-14T11:31:17.951110Z","shell.execute_reply.started":"2024-04-14T11:31:16.602817Z","shell.execute_reply":"2024-04-14T11:31:17.949742Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e4/sample_submission.csv\n/kaggle/input/playground-series-s4e4/train.csv\n/kaggle/input/playground-series-s4e4/test.csv\n/kaggle/input/abalone1/abalone.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2024-04-14T11:31:21.942745Z","iopub.execute_input":"2024-04-14T11:31:21.943358Z","iopub.status.idle":"2024-04-14T11:31:37.627239Z","shell.execute_reply.started":"2024-04-14T11:31:21.943321Z","shell.execute_reply":"2024-04-14T11:31:37.625548Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pytorch-tabnet\n  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.26.4)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.2.2)\nRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.11.4)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (2.1.2+cpu)\nRequirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (4.66.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\nDownloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-4.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset_root = r\"/kaggle/input/playground-series-s4e4/train.csv\"\ntrain_dataset_root2 = r\"/kaggle/input/abalone1/abalone.csv\"\ntest_dataset_root = r\"/kaggle/input/playground-series-s4e4/test.csv\"\ntrain_dataset = pd.read_csv(train_dataset_root)\n# one hot\ntrain_dataset = pd.get_dummies(train_dataset, columns=['Sex'])\ntest_dataset = pd.read_csv(test_dataset_root)\ntest_dataset = pd.get_dummies(test_dataset, columns=['Sex'])\n# print(train_dataset.head(3))\ntrain_dataset2 = pd.read_csv(train_dataset_root2)\ntrain_dataset2 = pd.get_dummies(train_dataset2, columns=['Sex'])\ntrain_dataset2 = train_dataset2.rename(columns={'Shucked weight': 'Whole weight.1', 'Viscera weight': 'Whole weight.2'})\nprint(train_dataset2.head(3))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T11:31:48.102961Z","iopub.execute_input":"2024-04-14T11:31:48.104203Z","iopub.status.idle":"2024-04-14T11:31:48.474448Z","shell.execute_reply.started":"2024-04-14T11:31:48.104132Z","shell.execute_reply":"2024-04-14T11:31:48.472926Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"   Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n\n   Shell weight  Rings  Sex_F  Sex_I  Sex_M  \n0          0.15     15  False  False   True  \n1          0.07      7  False  False   True  \n2          0.21      9   True  False  False  \n","output_type":"stream"}]},{"cell_type":"code","source":"X = train_dataset.drop(columns=[\"id\",\"Rings\"]).values  # feature\nX2 = train_dataset2.drop(columns=[\"Rings\"]).values\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of X2:\", X2.shape)\nX = np.concatenate((X, X2), axis=0)\ny = train_dataset['Rings'].values  # label\ny2 = train_dataset2['Rings'].values  # label\ny = np.concatenate((y, y2), axis=0)\nprint(X)\nprint(X2)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T11:33:22.184557Z","iopub.execute_input":"2024-04-14T11:33:22.185271Z","iopub.status.idle":"2024-04-14T11:33:22.272599Z","shell.execute_reply.started":"2024-04-14T11:33:22.185221Z","shell.execute_reply":"2024-04-14T11:33:22.271182Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape of X: (90615, 10)\nShape of X2: (4177, 10)\n[[0.55 0.43 0.15 ... True False False]\n [0.63 0.49 0.145 ... True False False]\n [0.16 0.11 0.025 ... False True False]\n ...\n [0.6 0.475 0.205 ... False False True]\n [0.625 0.485 0.15 ... True False False]\n [0.71 0.555 0.195 ... False False True]]\n[[0.455 0.365 0.095 ... False False True]\n [0.35 0.265 0.09 ... False False True]\n [0.53 0.42 0.135 ... True False False]\n ...\n [0.6 0.475 0.205 ... False False True]\n [0.625 0.485 0.15 ... True False False]\n [0.71 0.555 0.195 ... False False True]]\n[11 11  6 ...  9 10 12]\n","output_type":"stream"}]},{"cell_type":"code","source":"sex_features = X[:,-3:]\nX_without_sex = X[:, :-3]\nsex_features_numeric = sex_features.astype(int)\nprint(X.shape)\nprint(sex_features.shape)\nprint(X_without_sex.shape)\nprint(sex_features_numeric)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T11:56:36.297415Z","iopub.execute_input":"2024-04-14T11:56:36.297902Z","iopub.status.idle":"2024-04-14T11:56:36.318773Z","shell.execute_reply.started":"2024-04-14T11:56:36.297867Z","shell.execute_reply":"2024-04-14T11:56:36.317522Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(94792, 10)\n(94792, 3)\n(94792, 7)\n[[1 0 0]\n [1 0 0]\n [0 1 0]\n ...\n [0 0 1]\n [1 0 0]\n [0 0 1]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Preprocess**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nscaler = StandardScaler()\nX_scaled_ws = scaler.fit_transform(X_without_sex)\nX_scaled = np.concatenate((X_scaled_ws, sex_features_numeric), axis=1)\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\nprint(X_train)\n\ny_train = np.reshape(y_train, (-1, 1))\ny_val = np.reshape(y_val, (-1, 1))\nprint(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T11:58:17.636341Z","iopub.execute_input":"2024-04-14T11:58:17.636841Z","iopub.status.idle":"2024-04-14T11:58:17.707909Z","shell.execute_reply.started":"2024-04-14T11:58:17.636807Z","shell.execute_reply":"2024-04-14T11:58:17.706859Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[[-2.2602359  -2.21182968 -2.11147625 ...  0.          1.\n   0.        ]\n [ 1.71247228  1.86616924  1.5541619  ...  0.          0.\n   1.        ]\n [ 1.28984375  1.20349441  1.03049931 ...  0.          0.\n   1.        ]\n ...\n [ 0.10648387  0.18399468 -0.27865717 ...  0.          1.\n   0.        ]\n [ 1.50115802  1.2544694   1.29233061 ...  0.          0.\n   1.        ]\n [-1.24592743 -1.29427992 -1.06415106 ...  0.          1.\n   0.        ]]\n[[ 4]\n [11]\n [ 9]\n ...\n [ 8]\n [11]\n [ 7]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor\n\nclf = TabNetRegressor(n_d=16, n_a=16, n_steps=4, cat_idxs=[7,8,9], cat_dims=[2,2,2], device_name=\"cuda\")\nclf.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    eval_metric=['rmsle']\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:01:13.624595Z","iopub.execute_input":"2024-04-14T12:01:13.625337Z","iopub.status.idle":"2024-04-14T12:07:26.652285Z","shell.execute_reply.started":"2024-04-14T12:01:13.625299Z","shell.execute_reply":"2024-04-14T12:07:26.650879Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n  warnings.warn(f\"Device used : {self.device}\")\n","output_type":"stream"},{"name":"stdout","text":"epoch 0  | loss: 9.37049 | val_0_rmsle: 0.20539 |  0:00:06s\nepoch 1  | loss: 4.18891 | val_0_rmsle: 0.1689  |  0:00:12s\nepoch 2  | loss: 3.98013 | val_0_rmsle: 0.16316 |  0:00:18s\nepoch 3  | loss: 3.93408 | val_0_rmsle: 0.15813 |  0:00:24s\nepoch 4  | loss: 3.81768 | val_0_rmsle: 0.16021 |  0:00:31s\nepoch 5  | loss: 3.84831 | val_0_rmsle: 0.15749 |  0:00:38s\nepoch 6  | loss: 3.9073  | val_0_rmsle: 0.16017 |  0:00:44s\nepoch 7  | loss: 3.88582 | val_0_rmsle: 0.15988 |  0:00:50s\nepoch 8  | loss: 3.77875 | val_0_rmsle: 0.15742 |  0:00:57s\nepoch 9  | loss: 3.72826 | val_0_rmsle: 0.15698 |  0:01:03s\nepoch 10 | loss: 3.73751 | val_0_rmsle: 0.15627 |  0:01:10s\nepoch 11 | loss: 3.71938 | val_0_rmsle: 0.15646 |  0:01:16s\nepoch 12 | loss: 3.6935  | val_0_rmsle: 0.15542 |  0:01:23s\nepoch 13 | loss: 3.67544 | val_0_rmsle: 0.15692 |  0:01:29s\nepoch 14 | loss: 3.70239 | val_0_rmsle: 0.1577  |  0:01:36s\nepoch 15 | loss: 3.66606 | val_0_rmsle: 0.15799 |  0:01:42s\nepoch 16 | loss: 3.67953 | val_0_rmsle: 0.15471 |  0:01:49s\nepoch 17 | loss: 3.69737 | val_0_rmsle: 0.15558 |  0:01:56s\nepoch 18 | loss: 3.69088 | val_0_rmsle: 0.15683 |  0:02:02s\nepoch 19 | loss: 3.65647 | val_0_rmsle: 0.15556 |  0:02:09s\nepoch 20 | loss: 3.65685 | val_0_rmsle: 0.16378 |  0:02:16s\nepoch 21 | loss: 3.63116 | val_0_rmsle: 0.16529 |  0:02:22s\nepoch 22 | loss: 3.65472 | val_0_rmsle: 0.15593 |  0:02:29s\nepoch 23 | loss: 3.63242 | val_0_rmsle: 0.15448 |  0:02:35s\nepoch 24 | loss: 3.65821 | val_0_rmsle: 0.15614 |  0:02:42s\nepoch 25 | loss: 3.63508 | val_0_rmsle: 0.15497 |  0:02:49s\nepoch 26 | loss: 3.65629 | val_0_rmsle: 0.15793 |  0:02:55s\nepoch 27 | loss: 3.61305 | val_0_rmsle: 0.15414 |  0:03:02s\nepoch 28 | loss: 3.63524 | val_0_rmsle: 0.15725 |  0:03:08s\nepoch 29 | loss: 3.61902 | val_0_rmsle: 0.15433 |  0:03:15s\nepoch 30 | loss: 3.62021 | val_0_rmsle: 0.15573 |  0:03:21s\nepoch 31 | loss: 3.64752 | val_0_rmsle: 0.15704 |  0:03:27s\nepoch 32 | loss: 3.66267 | val_0_rmsle: 0.15495 |  0:03:34s\nepoch 33 | loss: 3.5855  | val_0_rmsle: 0.15495 |  0:03:40s\nepoch 34 | loss: 3.6214  | val_0_rmsle: 0.1561  |  0:03:46s\nepoch 35 | loss: 3.60084 | val_0_rmsle: 0.15707 |  0:03:53s\nepoch 36 | loss: 3.58361 | val_0_rmsle: 0.15403 |  0:03:59s\nepoch 37 | loss: 3.63068 | val_0_rmsle: 0.15602 |  0:04:06s\nepoch 38 | loss: 3.58453 | val_0_rmsle: 0.15556 |  0:04:12s\nepoch 39 | loss: 3.59333 | val_0_rmsle: 0.16588 |  0:04:19s\nepoch 40 | loss: 3.59821 | val_0_rmsle: 0.15625 |  0:04:25s\nepoch 41 | loss: 3.65814 | val_0_rmsle: 0.15489 |  0:04:32s\nepoch 42 | loss: 3.61605 | val_0_rmsle: 0.15444 |  0:04:38s\nepoch 43 | loss: 3.61065 | val_0_rmsle: 0.15396 |  0:04:45s\nepoch 44 | loss: 3.59652 | val_0_rmsle: 0.15903 |  0:04:52s\nepoch 45 | loss: 3.60915 | val_0_rmsle: 0.1535  |  0:04:59s\nepoch 46 | loss: 3.60179 | val_0_rmsle: 0.15779 |  0:05:06s\nepoch 47 | loss: 3.5736  | val_0_rmsle: 0.15426 |  0:05:13s\nepoch 48 | loss: 3.69465 | val_0_rmsle: 0.1547  |  0:05:21s\nepoch 49 | loss: 3.57342 | val_0_rmsle: 0.15531 |  0:05:28s\nepoch 50 | loss: 3.57467 | val_0_rmsle: 0.15425 |  0:05:35s\nepoch 51 | loss: 3.57062 | val_0_rmsle: 0.1555  |  0:05:42s\nepoch 52 | loss: 3.5762  | val_0_rmsle: 0.15643 |  0:05:49s\nepoch 53 | loss: 3.59448 | val_0_rmsle: 0.15895 |  0:05:56s\nepoch 54 | loss: 3.58062 | val_0_rmsle: 0.15729 |  0:06:03s\nepoch 55 | loss: 3.58019 | val_0_rmsle: 0.15551 |  0:06:10s\n\nEarly stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_rmsle = 0.1535\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n  warnings.warn(wrn_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"X = test_dataset.drop(columns=[\"id\"]).values\ntest_id = test_dataset[\"id\"].values\nsex_features = X[:,-3:]\nX_without_sex = X[:, :-3]\nsex_features_numeric = sex_features.astype(int)\nscaler = StandardScaler()\nX_scaled_ws = scaler.fit_transform(X_without_sex)\ntest_scaled = np.concatenate((X_scaled_ws, sex_features_numeric), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:08:18.131097Z","iopub.execute_input":"2024-04-14T12:08:18.131597Z","iopub.status.idle":"2024-04-14T12:08:18.217615Z","shell.execute_reply.started":"2024-04-14T12:08:18.131564Z","shell.execute_reply":"2024-04-14T12:08:18.216228Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"preds = clf.predict(test_scaled)\nprint(preds)\nprint(preds.flatten())","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:09:35.094602Z","iopub.execute_input":"2024-04-14T12:09:35.095710Z","iopub.status.idle":"2024-04-14T12:09:36.961211Z","shell.execute_reply.started":"2024-04-14T12:09:35.095664Z","shell.execute_reply":"2024-04-14T12:09:36.959519Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[[ 9.520769]\n [ 9.534084]\n [10.019717]\n ...\n [12.626135]\n [12.96019 ]\n [ 8.480943]]\n[ 9.520769  9.534084 10.019717 ... 12.626135 12.96019   8.480943]\n","output_type":"stream"}]},{"cell_type":"code","source":"result_df = pd.DataFrame({'id': test_id, 'Rings': preds.flatten()})\n# 将DataFrame保存到CSV文件中\nresult_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":31,"outputs":[]}]}